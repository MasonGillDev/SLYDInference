{
  "model": "HuggingFaceTB/SmolLM3-3B",
  "dtype": "auto",
  "gpu_memory_utilization": 0.95,
  "host": "0.0.0.0",
  "max_model_len": 2048,
  "max_num_seqs": 256,
  "model": "",
  "port": 8002,
  "tensor_parallel_size": 1,
  "trust_remote_code": false,
  "quantization": null,
  "seed": null,
  "swap_space": null,
  "block_size": null,
  "enable_prefix_caching": false,
  "enable_chunked_prefill": false,
  "max_num_batched_tokens": null,
  "max_paddings": null,
  "tokenizer": null,
  "tokenizer_pool_size": null,
  "chat_template": null,
  "response_role": "",
  "served_model_name": null,
  "disable_log_stats": false,
  "enable_lora": false,
  "max_loras": null,
  "max_lora_rank": null,
  "lora_dtype": "auto",
  "max_cpu_loras": null
}